{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other model will go here as well\n",
    "import LACER as lc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sgcrf import SparseGaussianCRF\n",
    "\n",
    "def preprocessing(df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filters dataframe by specified start and end_dates and runs CleanedFrame on it.  \n",
    "    \"\"\" \n",
    "\n",
    "    #Filter dataframe by dates \n",
    "    df = df[(df['Just Date'] >= start_date) & (df['Just Date'] <= end_date)]\n",
    "    df = lc.CleanedFrame(df)\n",
    "\n",
    "    return df\n",
    "def lacer(df, df1, train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num): #Once model is ready, replace df with csv\n",
    "    \"\"\"\n",
    "    Trains 3 GCRF models on data from specified CD, Request Type, and Owner which is assigned to fulfill request. \n",
    "    Uses specified start and end dates for training and testing to creat train and test sets. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create Training and Testing Sets\n",
    "    dftrain = preprocessing(df , train_start_date, train_end_date)\n",
    "    dftrain = dftrain.reset_index(drop = True)\n",
    "    dftest = preprocessing(df1, test_start_date, test_end_date)\n",
    "    dftest = dftest.reset_index(drop = True)\n",
    "\n",
    "    #Reserve test set for training on all 3 models. \n",
    "    y_train, y_test = lc.CreateTestSet(dftest, predictor_num)\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "\n",
    "## 2 Models\n",
    "    #Model1: CD\n",
    "    modelCD = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainCD = dftrain[dftrain['CD'] == CD].reset_index(drop = True)\n",
    "\n",
    "    X_trainCD, X_testCD = lc.CreateTrainSet(dftrainCD, predictor_num)\n",
    "    X_testCD = X_testCD.reshape((-1, 1))\n",
    "    modelCD.fit(X_trainCD, X_testCD)\n",
    "\n",
    "    y_predCD = modelCD.predict(y_train)\n",
    "\n",
    "    #Model2: Request_type\n",
    "    modelRT = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainRT = dftrain[dftrain['RequestType'] == request_type].reset_index(drop = True)\n",
    "\n",
    "    X_trainRT, X_testRT = lc.CreateTrainSet(dftrainRT, predictor_num)\n",
    "    X_testRT = X_testRT.reshape((-1, 1))\n",
    "\n",
    "    modelRT.fit(X_trainRT, X_testRT)\n",
    "\n",
    "    y_predRT = modelRT.predict(y_train)\n",
    "\n",
    "\n",
    "    #Average out all predictions\n",
    "    y_predFinal = (y_predCD + y_predRT )/2\n",
    "\n",
    "    #Return metrics \n",
    "    return lc.metrics(y_predFinal, y_test)\n",
    "\n",
    "def gelev(val): \n",
    "    \"\"\"\n",
    "    Records whether or not a number is greater than 7. \n",
    "    \"\"\"\n",
    "    if val <= 11: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "    \n",
    "def preprocess(df_path):\n",
    "    df = pd.read_csv(df_path)\n",
    "    df['Just Date'] = df['Just Date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d'))\n",
    "    df['Eleven'] = df['ElapsedDays'].apply(gelev, 0)\n",
    "    #Encode values\n",
    "    c = ['Anonymous','AssignTo', 'RequestType', 'RequestSource','CD','Direction', 'ActionTaken', 'APC' ,'AddressVerified']\n",
    "    d = ['Latitude', 'Longitude']\n",
    "    #Put desired columns into dataframe, drop nulls. \n",
    "    dfn = df.filter(items = c + d + ['ElapsedDays'])\n",
    "    dfn = dfn.dropna()\n",
    "    #Separate data into explanatory and response variables\n",
    "    XCAT = dfn.filter(items = c).values\n",
    "    XNUM = dfn.filter(items = d).values\n",
    "    y = dfn['ElapsedDays'] <= 11\n",
    "    #Encode cateogrical data and merge with numerical data\n",
    "    labelencoder_X = LabelEncoder()\n",
    "    for num in range(len(c)): \n",
    "        XCAT[:, num] = labelencoder_X.fit_transform(XCAT[:, num])\n",
    "    onehotencoder = OneHotEncoder()\n",
    "    XCAT = onehotencoder.fit_transform(XCAT).toarray()\n",
    "    X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "    return X,y, dfn\n",
    "\n",
    "#50,20\n",
    "def estimation_model(estimators, depth,X,y):    \n",
    "    rf = RandomForestClassifier(n_estimators = estimators, max_depth = depth)\n",
    "    print('creating train, test, val split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "    #Train Model\n",
    "    print('training model')\n",
    "    rf.fit(X_train, y_train)\n",
    "    #Test model\n",
    "    print('testing model')\n",
    "    y_vpred = rf.predict(X_val)\n",
    "    #Print Accuracy Function results\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_val, y_vpred))\n",
    "    print(\"Precision, Recall, F1Score:\",metrics.precision_recall_fscore_support(y_val, y_vpred, average = 'binary'))\n",
    "    return rf\n",
    "    \n",
    "def dummy_model(df):\n",
    "    return 0,0\n",
    "\n",
    "def split_to_models(df_file_path):\n",
    "    print('Calculating train data and labels')\n",
    "    X, y, df = preprocess(df_file_path)\n",
    "    df_clean = pd.read_csv(df_file_path)\n",
    "    print('Creating 11 day classifier')\n",
    "    model_eleven = estimation_model(50,20,X,y)\n",
    "    df['LessEqualEleven'] = model_eleven.predict(X)\n",
    "    df['LessEqualEleven'] = df['LessEqualEleven'].apply(lambda x: int(x))\n",
    "    df_sgcrf = df[df['LessEqualEleven'] == 1.0]\n",
    "    df_other = df[df['LessEqualEleven'] == 0.0]\n",
    "    return df_sgcrf.merge(df_clean,on=['Latitude','Longitude']), df_other\n",
    "\n",
    "def run_split_models(df_file_path,train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num):\n",
    "    df_sgcrf, df_other = split_to_models(df_file_path)\n",
    "    print('running SGCRF')\n",
    "    rmse, mae = lacer(df_sgcrf.copy(),df_sgcrf.copy(), train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num)\n",
    "    print('running (other model)')\n",
    "    a,b = dummy_model(df_other)\n",
    "    return (rmse,mae),(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating train data and labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DtypeWarning: Columns (10,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3296: DtypeWarning: Columns (10,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 11 day classifier\n",
      "creating train, test, val split\n",
      "training model\n",
      "testing model\n",
      "Accuracy: 0.9624896400663036\n",
      "Precision, Recall, F1Score: (0.9688614519736445, 0.9926608913765473, 0.9806167906238648, None)\n"
     ]
    }
   ],
   "source": [
    "u,v = run_split_models('fservice.csv',\"2018-01-01\", \"2018-06-01\", \"2018-06-02\", \"2018-09-02\",'Graffiti Removal',5,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
