{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code for piping the majority and minority classes to their appropriate models, and running the models\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Other model will go here as well\n",
    "import LACER as lc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sgcrf import SparseGaussianCRF\n",
    "import pickle\n",
    "\n",
    "#Features to use in our model, c = categorical, d = numeric\n",
    "c = ['Anonymous','AssignTo', 'RequestType', 'RequestSource','CD','Direction', 'ActionTaken', 'APC' ,'AddressVerified']\n",
    "d = ['Latitude', 'Longitude']\n",
    "    \n",
    "#Slightly editied lacer funcions\n",
    "def preprocessing(df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filters dataframe by specified start and end_dates and runs CleanedFrame on it.  \n",
    "    \"\"\" \n",
    "    #Filter dataframe by dates \n",
    "    df = df[(df['Just Date'] >= start_date) & (df['Just Date'] <= end_date)]\n",
    "    df = lc.CleanedFrame(df)\n",
    "    return df\n",
    "\n",
    "def lacer(df, df1, train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num):\n",
    "    \"\"\"\n",
    "    Trains 2 GCRF models on data from specified CD and Request Type which is assigned to fulfill request. \n",
    "    Uses specified start and end dates for training and testing to creat train and test sets. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create Training and Testing Sets\n",
    "    dftrain = preprocessing(df, train_start_date, train_end_date)\n",
    "    dftrain = dftrain.reset_index(drop = True)\n",
    "    dftest = preprocessing(df1, test_start_date, test_end_date)\n",
    "    dftest = dftest.reset_index(drop = True)\n",
    "\n",
    "    #Reserve test set for training on all 3 models.\n",
    "    \n",
    "    y_train, y_test = lc.CreateTestSet(dftest, predictor_num)\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "   \n",
    "\n",
    "    ## 2 Models\n",
    "    #Model1: CD\n",
    "    modelCD = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainCD = dftrain[dftrain['CD'] == CD].reset_index(drop = True)\n",
    "\n",
    "    X_trainCD, X_testCD = lc.CreateTrainSet(dftrainCD, predictor_num)\n",
    "    X_testCD = X_testCD.reshape((-1, 1))\n",
    "    modelCD.fit(X_trainCD, X_testCD)\n",
    "\n",
    "    y_predCD = modelCD.predict(y_train)\n",
    "\n",
    "    #Model2: Request_type\n",
    "    modelRT = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainRT = dftrain[dftrain['RequestType'] == request_type].reset_index(drop = True)\n",
    "\n",
    "    X_trainRT, X_testRT = lc.CreateTrainSet(dftrainRT, predictor_num)\n",
    "    X_testRT = X_testRT.reshape((-1, 1))\n",
    "\n",
    "    modelRT.fit(X_trainRT, X_testRT)\n",
    "\n",
    "    y_predRT = modelRT.predict(y_train)\n",
    "\n",
    "\n",
    "    #Average out all predictions\n",
    "    y_predFinal = (y_predCD + y_predRT )/2\n",
    "\n",
    "    # Return models\n",
    "    return modelCD, modelRT\n",
    "\n",
    "\"\"\"\n",
    "Retu whether or not a number is greater than 11. \n",
    "\"\"\"\n",
    "def gelev(val): \n",
    "    if val <= 11: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "'''\n",
    "Preprocessing function. Takes in the file path to the data and loads it in a DataFrame, then calcuates the elapsed days per request and marks them as more than or less than eleven days. Then it encodes the appropriate values and returns the train data, labels, and the formatted dataframe.\n",
    "'''\n",
    "def preprocess(df, formatted=False):\n",
    "    if not formatted:\n",
    "        df['Just Date'] = df['Just Date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d'))\n",
    "    df['Eleven'] = df['ElapsedDays'].apply(gelev, 0)\n",
    "    #Put desired columns into dataframe, drop nulls. \n",
    "    dfn = df.filter(items = c + d + ['ElapsedDays','Just Date','CreatedDate','ClosedDate'])\n",
    "    dfn = dfn.dropna()\n",
    "    \n",
    "    #Separate data into explanatory and response variables\n",
    "    XCAT = dfn.filter(items = c).values\n",
    "    XNUM = dfn.filter(items = d).values\n",
    "    y = dfn['ElapsedDays'] <= 11\n",
    "    \n",
    "    #Encode cateogrical data and merge with numerical data\n",
    "    onehotencoder = OneHotEncoder()\n",
    "    #Dump encoder class data to pickle\n",
    "    pickle.dump(onehotencoder, open(\"encoder.pickl\", \"wb\"))\n",
    "    XCAT = onehotencoder.fit_transform(XCAT).toarray()\n",
    "    X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "    return X,y, dfn\n",
    "\n",
    "'''\n",
    "Runs the model that classifies each request as more than or less than/equal to 11 days. Parameters are the hyperparameters for the model itself, and the train data and labels.\n",
    "'''\n",
    "def estimation_model(estimators, depth,X,y):    \n",
    "    rf = RandomForestClassifier(n_estimators = estimators, max_depth = depth)\n",
    "    print('creating train, test, val split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "    #Train Model on 3 yrs data on\n",
    "    print('training model')\n",
    "    rf.fit(X_train, y_train)\n",
    "    #Test model\n",
    "    print('testing model')\n",
    "    y_vpred = rf.predict(X_val)\n",
    "    print('dump to pickle')\n",
    "    pickle.dump(rf, open('randomForest.pkl', 'wb'))\n",
    "    #Print Accuracy Function results\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_val, y_vpred))\n",
    "    print(\"Precision, Recall, F1Score:\",metrics.precision_recall_fscore_support(y_val, y_vpred, average = 'binary'))\n",
    "    return rf\n",
    "\n",
    "'''\n",
    "Will be replaced with model for requests over 11 days\n",
    "'''\n",
    "def minority_class_model(df):\n",
    "    # this needs to return a model for the deployment to work -- Andy\n",
    "    return 0,0\n",
    "\n",
    "'''\n",
    "Takes a file path to the data, runs the appropriate preprocessing steps, and uses the model to classify everything into the majority and minority class. Returns a dataframe with the majority class and a separate one with the minority class.\n",
    "'''\n",
    "def split_to_models(df,formatted=False):\n",
    "    print('Calculating train data and labels')\n",
    "    X, y, df = preprocess(df,formatted)\n",
    "    print('Creating 11 day classifier')\n",
    "    #Train on 3 yrs before data\n",
    "    model_eleven = estimation_model(50,20,X,y)\n",
    "    df['LessEqualEleven'] = model_eleven.predict(X)\n",
    "    df['LessEqualEleven'] = df['LessEqualEleven'].apply(lambda x: int(x))\n",
    "    df_sgcrf = df[df['LessEqualEleven'] == 1.0]\n",
    "    df_other = df[df['LessEqualEleven'] == 0.0]\n",
    "    return df_sgcrf, df_other\n",
    "\n",
    "'''\n",
    "Takes the data file path and parameters for the lacer model and runs the pipeline to get the appropriate dataframes, then runs both models. This is the main function you should run from this file.\n",
    "'''\n",
    "'''\n",
    "def create_split_models(df,train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num):\n",
    "    df_sgcrf, df_other = split_to_models(df)\n",
    "    print('running SGCRF')\n",
    "    #10 weeks\n",
    "    modelCD, modelRT = lacer(df_sgcrf.copy(),df_sgcrf.copy(), train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num)\n",
    "    print('running (other model)')\n",
    "    #a,b = minority_class_model(df_other)\n",
    "    \n",
    "    # send to pickle so that flask can access it\n",
    "    print('dumping to pickle')\n",
    "    pickle.dump(modelCD, open('modelCD.pkl','wb'))\n",
    "    pickle.dump(modelRT, open('modelRT.pkl','wb'))\n",
    "    #return (modelCD, modelRT), (a, b)\n",
    "'''\n",
    "#Demo code\n",
    "def create_models(df,start_date, request_type, CD, predictor_num):\n",
    "    start = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "    X, y, dfn = preprocess(df)\n",
    "    #past three years\n",
    "    df_three = dfn[(dfn['Just Date'] <= start-timedelta(weeks=11)) &\n",
    "                   (dfn['Just Date'] >= start-timedelta(weeks=11) - timedelta(days=365*3))]\n",
    "    df_sgcrf,ignore = split_to_models(df_three,True)\n",
    "    train_end_date = df_sgcrf.iloc[-50]['Just Date']\n",
    "    modelCD, modelRT = lacer(df_sgcrf.copy(),df_sgcrf.copy(), train_end_date - timedelta(weeks=10), train_end_date, \"2017-06-02\", \"2017-09-02\", request_type, CD, predictor_num)\n",
    "    pickle.dump(modelCD, open('modelCD.pkl','wb'))\n",
    "    pickle.dump(modelRT, open('modelRT.pkl','wb'))\n",
    "    #return (modelCD, modelRT), (a, b)\n",
    "\n",
    "'''\n",
    "Beginning code to update the model after requests have been made.\n",
    "'''\n",
    "def update_model(requests,modelCD,modelRT,modelMin):\n",
    "    df_request = pd.DataFrame(data=requests,columns=c+d)\n",
    "    X, y, df = preprocess(df_request)\n",
    "    df_sgcrf = df[df['ElapsedDays'] <= 11.0]\n",
    "    df_other = df[df['ElapsedDays'] > 11.0]\n",
    "    modelCD.fit(np.asarray(df_sgcrf['CD']),np.asarray(df_sgcrf['ElapsedDays']))\n",
    "    modelRT.fit(np.asarray(df_sgcrf['RequestType']),np.asarray(df_sgcrf['ElapsedDays']))\n",
    "    #modelMin.fit will go here\n",
    "    #dump back to pickle - or we can just return the models themselves\n",
    "    pickle.dump(modelCD, open('modelCD.pkl'), 'wb')\n",
    "    pickle.dump(modelRT, open('modelRT.pkl'), 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating train data and labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 11 day classifier\n",
      "creating train, test, val split\n",
      "training model\n",
      "testing model\n",
      "dump to pickle\n",
      "Accuracy: 0.9657530375812376\n",
      "Precision, Recall, F1Score: (0.9719114610841696, 0.9930240087911225, 0.9823543114493147, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ElapsedHours'] = df.apply(lambda x: elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ClosedDate'] = df['ClosedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['CreatedDate'] = df['CreatedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ElapsedHours'] = df.apply(lambda x: elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ClosedDate'] = df['ClosedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['CreatedDate'] = df['CreatedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "100% |########################################################################|\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "create_models(pd.read_csv('fservice.csv'),'2018-01-01','Graffiti Removal',5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "X,y, dfn = preprocess(pd.read_csv('fservice.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anonymous</th>\n",
       "      <th>AssignTo</th>\n",
       "      <th>RequestType</th>\n",
       "      <th>RequestSource</th>\n",
       "      <th>CD</th>\n",
       "      <th>Direction</th>\n",
       "      <th>ActionTaken</th>\n",
       "      <th>APC</th>\n",
       "      <th>AddressVerified</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ElapsedDays</th>\n",
       "      <th>Just Date</th>\n",
       "      <th>CreatedDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>CCAC</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>13.0</td>\n",
       "      <td>N</td>\n",
       "      <td>SR Created</td>\n",
       "      <td>East Los Angeles APC</td>\n",
       "      <td>Y</td>\n",
       "      <td>34.084714</td>\n",
       "      <td>-118.260479</td>\n",
       "      <td>11</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01/01/2017 12:45:00 AM</td>\n",
       "      <td>01/12/2017 05:10:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>12.0</td>\n",
       "      <td>W</td>\n",
       "      <td>SR Created</td>\n",
       "      <td>North Valley APC</td>\n",
       "      <td>Y</td>\n",
       "      <td>34.256993</td>\n",
       "      <td>-118.604730</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01/01/2017 01:01:00 AM</td>\n",
       "      <td>01/04/2017 05:33:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>12.0</td>\n",
       "      <td>W</td>\n",
       "      <td>SR Created</td>\n",
       "      <td>North Valley APC</td>\n",
       "      <td>Y</td>\n",
       "      <td>34.257061</td>\n",
       "      <td>-118.594999</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01/01/2017 01:09:00 AM</td>\n",
       "      <td>01/04/2017 05:34:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y</td>\n",
       "      <td>NEGB_ELA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td>SR Created</td>\n",
       "      <td>East Los Angeles APC</td>\n",
       "      <td>Y</td>\n",
       "      <td>34.090852</td>\n",
       "      <td>-118.226214</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01/01/2017 01:16:00 AM</td>\n",
       "      <td>01/03/2017 06:55:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N</td>\n",
       "      <td>NC</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N</td>\n",
       "      <td>SR Created</td>\n",
       "      <td>Central APC</td>\n",
       "      <td>Y</td>\n",
       "      <td>34.084822</td>\n",
       "      <td>-118.333307</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>01/01/2017 01:21:00 AM</td>\n",
       "      <td>01/07/2017 09:46:00 AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Anonymous  AssignTo       RequestType RequestSource    CD Direction  \\\n",
       "1         Y      CCAC  Graffiti Removal    Mobile App  13.0         N   \n",
       "3         N       WVA  Graffiti Removal    Mobile App  12.0         W   \n",
       "4         N       WVA  Graffiti Removal    Mobile App  12.0         W   \n",
       "5         Y  NEGB_ELA  Graffiti Removal    Mobile App   1.0         E   \n",
       "6         N        NC       Bulky Items    Mobile App   4.0         N   \n",
       "\n",
       "  ActionTaken                   APC AddressVerified   Latitude   Longitude  \\\n",
       "1  SR Created  East Los Angeles APC               Y  34.084714 -118.260479   \n",
       "3  SR Created      North Valley APC               Y  34.256993 -118.604730   \n",
       "4  SR Created      North Valley APC               Y  34.257061 -118.594999   \n",
       "5  SR Created  East Los Angeles APC               Y  34.090852 -118.226214   \n",
       "6  SR Created           Central APC               Y  34.084822 -118.333307   \n",
       "\n",
       "   ElapsedDays  Just Date             CreatedDate              ClosedDate  \n",
       "1           11 2017-01-01  01/01/2017 12:45:00 AM  01/12/2017 05:10:00 PM  \n",
       "3            3 2017-01-01  01/01/2017 01:01:00 AM  01/04/2017 05:33:00 PM  \n",
       "4            3 2017-01-01  01/01/2017 01:09:00 AM  01/04/2017 05:34:00 PM  \n",
       "5            2 2017-01-01  01/01/2017 01:16:00 AM  01/03/2017 06:55:00 PM  \n",
       "6            6 2017-01-01  01/01/2017 01:21:00 AM  01/07/2017 09:46:00 AM  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Anonymous', 'AssignTo', 'RequestType', 'RequestSource', 'CD',\n",
       "       'Direction', 'ActionTaken', 'APC', 'AddressVerified', 'Latitude',\n",
       "       'Longitude', 'ElapsedDays', 'Just Date', 'CreatedDate', 'ClosedDate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
