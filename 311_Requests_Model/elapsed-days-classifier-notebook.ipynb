{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Code for piping the majority and minority classes to their appropriate models, and running the models\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Other model will go here as well\n",
    "import LACER as lc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sgcrf import SparseGaussianCRF\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Features to use in our model, c = categorical, d = numeric\n",
    "c = ['AssignTo', 'RequestType', 'RequestSource', 'Month', 'Anonymous', 'CreatedByUserOrganization']\n",
    "d = ['Latitude', 'Longitude']\n",
    "    \n",
    "#Slightly editied lacer funcions\n",
    "def preprocessing(df, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Filters dataframe by specified start and end_dates and runs CleanedFrame on it.  \n",
    "    \"\"\" \n",
    "    #Filter dataframe by dates \n",
    "    df = df[(df['Just Date'] >= start_date) & (df['Just Date'] <= end_date)]\n",
    "    df = lc.CleanedFrame(df)\n",
    "    return df\n",
    "\n",
    "def lacer(df, df1, train_start_date, train_end_date, test_start_date, test_end_date, request_type, CD, predictor_num):\n",
    "    \"\"\"\n",
    "    Trains 2 GCRF models on data from specified CD and Request Type which is assigned to fulfill request. \n",
    "    Uses specified start and end dates for training and testing to creat train and test sets. \n",
    "    \"\"\"\n",
    "\n",
    "    #Create Training and Testing Sets\n",
    "    dftrain = preprocessing(df, train_start_date, train_end_date)\n",
    "    dftrain = dftrain.reset_index(drop = True)\n",
    "    dftest = preprocessing(df1, test_start_date, test_end_date)\n",
    "    dftest = dftest.reset_index(drop = True)\n",
    "\n",
    "    #Reserve test set for training on all 3 models.\n",
    "    \n",
    "    y_train, y_test = lc.CreateTestSet(dftest, predictor_num)\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "   \n",
    "\n",
    "    ## 2 Models\n",
    "    #Model1: CD\n",
    "    modelCD = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainCD = dftrain[dftrain['CD'] == CD].reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    X_trainCD, X_testCD = lc.CreateTrainSet(dftrainCD, predictor_num)\n",
    "    X_testCD = X_testCD.reshape((-1, 1))\n",
    "    modelCD.fit(X_trainCD, X_testCD)\n",
    "\n",
    "    y_predCD = modelCD.predict(y_train)\n",
    "\n",
    "    #Model2: Request_type\n",
    "    modelRT = SparseGaussianCRF(lamL=0.1, lamT=0.1, n_iter=10000)\n",
    "    dftrainRT = dftrain[dftrain['RequestType'] == request_type].reset_index(drop = True)\n",
    "\n",
    "    X_trainRT, X_testRT = lc.CreateTrainSet(dftrainRT, predictor_num)\n",
    "    X_testRT = X_testRT.reshape((-1, 1))\n",
    "\n",
    "    modelRT.fit(X_trainRT, X_testRT)\n",
    "\n",
    "    y_predRT = modelRT.predict(y_train)\n",
    "\n",
    "\n",
    "    #Average out all predictions\n",
    "    y_predFinal = (y_predCD + y_predRT )/2\n",
    "\n",
    "    # Return models\n",
    "    return modelCD, modelRT\n",
    "\n",
    "\"\"\"\n",
    "Retu whether or not a number is greater than 11. \n",
    "\"\"\"\n",
    "def gelev(val): \n",
    "    if val <= 11: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "'''\n",
    "Preprocessing function. Takes in the file path to the data and loads it in a DataFrame, \n",
    "then calcuates the elapsed days per request and marks them as more than or less than eleven days. \n",
    "Then it encodes the appropriate values and returns the train data, labels, and the formatted dataframe.\n",
    "If formatted is False, it will convert the Just Date column into datetime objects\n",
    "If encode is false, it requires that the onehotencoder has already been dumped into a joblib file,\n",
    "so make sure that this has been run once on all the data with encode equal to true.\n",
    "'''\n",
    "def preprocess(df, formatted=False,encode=False):\n",
    "    if not formatted:\n",
    "        df['Just Date'] = df['Just Date'].apply(lambda x: datetime.strptime(x,'%Y-%m-%d'))\n",
    "    df['Eleven'] = df['ElapsedDays'].apply(gelev, 0)\n",
    "    df['Month'] = df['Just Date'].dt.month_name()\n",
    "    #Put desired columns into dataframe, drop nulls. \n",
    "    dfn = df.filter(items = c + d + ['ElapsedDays','Just Date','CreatedDate','ClosedDate','CD'])\n",
    "    dfn = dfn.dropna()\n",
    "    #Separate data into explanatory and response variables\n",
    "    XCAT = dfn.filter(items = c).values\n",
    "    XNUM = dfn.filter(items = d).values\n",
    "    y = dfn['ElapsedDays'] <= 11\n",
    "    #Encode cateogrical data and merge with numerical data\n",
    "    if encode:\n",
    "        onehotencoder = OneHotEncoder()\n",
    "        print(XCAT.shape)\n",
    "        onehotencoder.fit_transform(XCAT)\n",
    "        #XCAT = onehotencoder.fit_transform(XCAT).toarray()\n",
    "        X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "        print()\n",
    "        dump(onehotencoder,'onehot.joblib')\n",
    "        #pickle.dump(onehotencoder, open(\"encoder.pkl\", \"wb\"))\n",
    "    else:\n",
    "        onehotencoder = load('onehot.joblib')\n",
    "        XCAT = onehotencoder.transform(XCAT).toarray()\n",
    "        X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "    return X,y, dfn\n",
    "\n",
    "'''\n",
    "Preprocess a request given as a dataframe\n",
    "'''\n",
    "def preprocess_request(df):\n",
    "    dfn = df.filter(items = c + d)\n",
    "    dfn = dfn.dropna()\n",
    "    #Separate data into explanatory and response variables\n",
    "    XCAT = dfn.filter(items = c).values\n",
    "    XNUM = dfn.filter(items = d).values\n",
    "    y = None\n",
    "    #Encode cateogrical data and merge with numerical data\n",
    "    onehotencoder = load('onehot.joblib')\n",
    "    XCAT = onehotencoder.transform(XCAT).toarray()\n",
    "    X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "    return X, dfn\n",
    "\n",
    "'''\n",
    "Runs the model that classifies each request as more than or less than/equal to 11 days. \n",
    "Parameters are the hyperparameters for the model itself, and the train data and labels.\n",
    "'''\n",
    "def estimation_model(estimators, depth,X,y):    \n",
    "    rf = RandomForestClassifier(n_estimators = estimators, max_depth = depth)\n",
    "    print('creating train, test, val split')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 0)\n",
    "    #Train Model on 3 yrs data on\n",
    "    print('training model')\n",
    "    rf.fit(X_train, y_train)\n",
    "    #Test model\n",
    "    print('testing model')\n",
    "    y_vpred = rf.predict(X_val)\n",
    "    print('dump to pickle')\n",
    "    pickle.dump(rf, open('randomForest.pkl', 'wb'))\n",
    "    #Print Accuracy Function results\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_val, y_vpred))\n",
    "    print(\"Precision, Recall, F1Score:\",metrics.precision_recall_fscore_support(y_val, y_vpred, average = 'binary'))\n",
    "    return rf\n",
    "\n",
    "'''\n",
    "Takes a file path to the data, runs the appropriate preprocessing steps, and uses the model to classify everything into the majority and minority class. Returns a dataframe with the majority class and a separate one with the minority class.\n",
    "'''\n",
    "def split_to_models(df,formatted=False, encode=True):\n",
    "    print('Calculating train data and labels')\n",
    "    X, y, df = preprocess(df,formatted)\n",
    "    print('Creating 11 day classifier')\n",
    "    #Train on 3 yrs before data\n",
    "    print(X.shape)\n",
    "    model_eleven = estimation_model(50,20,X,y)\n",
    "    df['LessEqualEleven'] = model_eleven.predict(X)\n",
    "    df['LessEqualEleven'] = df['LessEqualEleven'].apply(lambda x: int(x))\n",
    "    df_sgcrf = df[df['LessEqualEleven'] == 1.0]\n",
    "    df_other = df[df['LessEqualEleven'] == 0.0]\n",
    "    return df_sgcrf, df_other\n",
    "\n",
    "'''\n",
    "Given a start date, it will train the classifier on data 3 years before 10 weeks before the start date, then \n",
    "train the sgcrf model with 10 weeks of data from before the start date, then predict using the fifty most recent requests\n",
    "from the start date.\n",
    "'''\n",
    "#Demo code\n",
    "def create_models(df,start_date, request_type, CD, predictor_num):\n",
    "    start = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "    #Preprocess data\n",
    "    X, y, dfn = preprocess(df,encode=True)\n",
    "    #Sort into past three years\n",
    "    df_three = dfn[(dfn['Just Date'] <= start-timedelta(weeks=11)) &\n",
    "                   (dfn['Just Date'] >= start-timedelta(weeks=11)+relativedelta(years=-3) )]\n",
    "    #Run dataframe through the classifier and get all requests less than or equal to 11 days\n",
    "    df_sgcrf,ignore = split_to_models(df_three,True)\n",
    "    #Get last 50 requests\n",
    "    dff = df_sgcrf.copy().tail(50).reset_index(drop=True)\n",
    "    dff['ElapsedHours'] = dff.apply(lambda x: lc.elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
    "    #Last 50 elapsedhours values\n",
    "    fifty = dff['ElapsedHours'].values\n",
    "    #Dump to npy file to be used by website backend\n",
    "    np.save(open('previousfifty.npy','wb'),fifty)\n",
    "    #Date of the 50th request from the end\n",
    "    train_end_date = df_sgcrf.iloc[-50]['Just Date']\n",
    "    #Send to LACER\n",
    "    modelCD, modelRT = lacer(df_sgcrf.copy(),df_sgcrf.copy(), train_end_date - timedelta(weeks=10), train_end_date, train_end_date - timedelta(weeks=10), train_end_date, request_type, CD, predictor_num)\n",
    "    #Dump to pickle file\n",
    "    pickle.dump(modelCD, open('modelCD.pkl','wb'))\n",
    "    pickle.dump(modelRT, open('modelRT.pkl','wb'))\n",
    "\n",
    "'''\n",
    "Beginning code to update the model after requests have been made.\n",
    "'''\n",
    "def update_model(requests,modelCD,modelRT,modelMin):\n",
    "    df_request = pd.DataFrame(data=requests,columns=c+d)\n",
    "    X, y, df = preprocess(df_request)\n",
    "    df_sgcrf = df[df['ElapsedDays'] <= 11.0]\n",
    "    df_other = df[df['ElapsedDays'] > 11.0]\n",
    "    modelCD.fit(np.asarray(df_sgcrf['CD']),np.asarray(df_sgcrf['ElapsedDays']))\n",
    "    modelRT.fit(np.asarray(df_sgcrf['RequestType']),np.asarray(df_sgcrf['ElapsedDays']))\n",
    "    #modelMin.fit will go here\n",
    "    #dump back to pickle - or we can just return the models themselves\n",
    "    pickle.dump(modelCD, open('modelCD.pkl'), 'wb')\n",
    "    pickle.dump(modelRT, open('modelRT.pkl'), 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462397, 6)\n",
      "\n",
      "Calculating train data and labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 11 day classifier\n",
      "(1215942, 123)\n",
      "creating train, test, val split\n",
      "training model\n",
      "testing model\n",
      "dump to pickle\n",
      "Accuracy: 0.9558419129174355\n",
      "Precision, Recall, F1Score: (0.9649652897837594, 0.9890678502104643, 0.9768679201591862, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ElapsedHours'] = df.apply(lambda x: elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ClosedDate'] = df['ClosedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['CreatedDate'] = df['CreatedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ElapsedHours'] = df.apply(lambda x: elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['ClosedDate'] = df['ClosedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "C:\\Users\\ngeta\\p-requests\\311_Requests_Model\\LACER.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['CreatedDate'] = df['CreatedDate'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p'))\n",
      "100% |########################################################################|\n",
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# Run this to generate the pickle files for the random forest classifier, the 2 models, \n",
    "# the one hot encoder joblib(generated in preprocess), and the last fifty requests from the start data as an npy file.\n",
    "df_requests = pd.read_csv('2020service.csv')\n",
    "df_requests = df_requests[df_requests['RequestSource'] != 'Driver Self Report']\n",
    "create_models(df_requests,'2020-10-01','Graffiti Removal',5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462397, 6)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_requests = pd.read_csv('2020service.csv')\n",
    "df_requests = df_requests[df_requests['RequestSource'] != 'Driver Self Report']\n",
    "X,y, dfn = preprocess((df_requests),encode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b4731b4ca444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_requests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2020service.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nrows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1993\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1994\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1995\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1996\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1702\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1703\u001b[0m     \"\"\"\n\u001b[0;32m   1704\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_requests = pd.read_csv('2020service.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
       "       'August', 'September'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn.Month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngeta\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(679112, 6)\n",
      "\n",
      "Calculating train data and labels\n",
      "Creating 11 day classifier\n",
      "(679112, 111)\n",
      "creating train, test, val split\n",
      "training model\n",
      "testing model\n",
      "dump to pickle\n",
      "Accuracy: 0.9585120285666955\n",
      "Precision, Recall, F1Score: (0.9686860830236511, 0.9877894736842106, 0.9781445138269402, None)\n"
     ]
    }
   ],
   "source": [
    "start = datetime.strptime('2019-12-01','%Y-%m-%d')\n",
    "X, y, dfn = preprocess(pd.read_csv('fservice.csv'),encode=True)\n",
    " #past three years\n",
    "df_three = dfn[(dfn['Just Date'] <= start-timedelta(weeks=11)) &\n",
    "                (dfn['Just Date'] >= start-timedelta(weeks=11)+relativedelta(years=-2) )]\n",
    "df_sgcrf,ignore = split_to_models(df_three,True)\n",
    "train_end_date = df_sgcrf.iloc[-50]['Just Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssignTo</th>\n",
       "      <th>RequestType</th>\n",
       "      <th>RequestSource</th>\n",
       "      <th>Month</th>\n",
       "      <th>Anonymous</th>\n",
       "      <th>CreatedByUserOrganization</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ElapsedDays</th>\n",
       "      <th>Just Date</th>\n",
       "      <th>CreatedDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CD</th>\n",
       "      <th>LessEqualEleven</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2340578</th>\n",
       "      <td>NC</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service_SAN</td>\n",
       "      <td>34.082258</td>\n",
       "      <td>-118.312461</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:02:00 AM</td>\n",
       "      <td>01/04/2019 11:03:00 AM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340580</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.236888</td>\n",
       "      <td>-118.536385</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:10:00 AM</td>\n",
       "      <td>01/03/2019 12:27:00 AM</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340581</th>\n",
       "      <td>WV</td>\n",
       "      <td>Illegal Dumping Pickup</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.230222</td>\n",
       "      <td>-118.539758</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:19:00 AM</td>\n",
       "      <td>01/07/2019 09:39:00 AM</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340582</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.235078</td>\n",
       "      <td>-118.536392</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:28:00 AM</td>\n",
       "      <td>01/03/2019 12:28:00 AM</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340583</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.239704</td>\n",
       "      <td>-118.523064</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:32:00 AM</td>\n",
       "      <td>01/03/2019 04:27:00 PM</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AssignTo             RequestType RequestSource    Month Anonymous  \\\n",
       "2340578       NC             Bulky Items  Self Service  January         N   \n",
       "2340580      WVA        Graffiti Removal  Self Service  January         N   \n",
       "2340581       WV  Illegal Dumping Pickup  Self Service  January         N   \n",
       "2340582      WVA        Graffiti Removal  Self Service  January         N   \n",
       "2340583      WVA        Graffiti Removal  Self Service  January         N   \n",
       "\n",
       "        CreatedByUserOrganization   Latitude   Longitude  ElapsedDays  \\\n",
       "2340578          Self Service_SAN  34.082258 -118.312461            3   \n",
       "2340580              Self Service  34.236888 -118.536385            2   \n",
       "2340581              Self Service  34.230222 -118.539758            6   \n",
       "2340582              Self Service  34.235078 -118.536392            2   \n",
       "2340583              Self Service  34.239704 -118.523064            2   \n",
       "\n",
       "         Just Date             CreatedDate              ClosedDate    CD  \\\n",
       "2340578 2019-01-01  01/01/2019 12:02:00 AM  01/04/2019 11:03:00 AM   4.0   \n",
       "2340580 2019-01-01  01/01/2019 12:10:00 AM  01/03/2019 12:27:00 AM  12.0   \n",
       "2340581 2019-01-01  01/01/2019 12:19:00 AM  01/07/2019 09:39:00 AM  12.0   \n",
       "2340582 2019-01-01  01/01/2019 12:28:00 AM  01/03/2019 12:28:00 AM  12.0   \n",
       "2340583 2019-01-01  01/01/2019 12:32:00 AM  01/03/2019 04:27:00 PM  12.0   \n",
       "\n",
       "         LessEqualEleven  \n",
       "2340578                1  \n",
       "2340580                1  \n",
       "2340581                1  \n",
       "2340582                1  \n",
       "2340583                1  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sgcrf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_sgcrf.copy().tail(50).reset_index(drop=True)\n",
    "dff['ElapsedHours'] = dff.apply(lambda x: lc.elapsedHours(x['CreatedDate'],x['ClosedDate']),axis=1)\n",
    "fifty = dff['ElapsedHours'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open('previousfifty.npy','wb'),fifty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 16.87361111,  12.4125    , 129.1325    ,  39.90722222,\n",
       "         8.385     ,  10.89694444, 107.19444444,  17.26333333,\n",
       "       133.45138889,  72.7525    , 114.03305556,  10.865     ,\n",
       "        17.99833333,  16.08138889,  88.67666667, 105.08583333,\n",
       "         8.80861111,  13.59305556, 129.20055556, 112.40083333,\n",
       "       144.55638889, -23.45611111,  16.06916667,  12.50944444,\n",
       "        12.73777778,  11.18888889,  15.65194444,  80.22694444,\n",
       "        17.04777778,  15.53361111,  16.15444444,  15.27305556,\n",
       "        16.14027778,  14.51972222,  16.03583333,  87.40166667,\n",
       "        80.27611111, 294.07472222,  89.53222222,  14.50444444,\n",
       "       108.68333333,  80.76861111,  15.51638889,  85.61611111,\n",
       "         7.68527778, 155.09527778, 127.21833333,  83.29722222,\n",
       "       138.79638889,  26.59305556])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load(open('previousfifty.npy','rb'))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssignTo</th>\n",
       "      <th>RequestType</th>\n",
       "      <th>RequestSource</th>\n",
       "      <th>Month</th>\n",
       "      <th>Anonymous</th>\n",
       "      <th>CreatedByUserOrganization</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ElapsedDays</th>\n",
       "      <th>Just Date</th>\n",
       "      <th>CreatedDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CD</th>\n",
       "      <th>LessEqualEleven</th>\n",
       "      <th>ElapsedHours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3030758</th>\n",
       "      <td>EV</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Call</td>\n",
       "      <td>July</td>\n",
       "      <td>N</td>\n",
       "      <td>BOS</td>\n",
       "      <td>34.178507</td>\n",
       "      <td>-118.362879</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>07/21/2019 08:11:00 PM</td>\n",
       "      <td>07/23/2019 09:28:00 AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030759</th>\n",
       "      <td>NC</td>\n",
       "      <td>Illegal Dumping Pickup</td>\n",
       "      <td>Call</td>\n",
       "      <td>July</td>\n",
       "      <td>N</td>\n",
       "      <td>BOS</td>\n",
       "      <td>34.056775</td>\n",
       "      <td>-118.297845</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>07/21/2019 08:12:00 PM</td>\n",
       "      <td>07/26/2019 05:14:00 PM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>117.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030760</th>\n",
       "      <td>EV</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Call</td>\n",
       "      <td>July</td>\n",
       "      <td>N</td>\n",
       "      <td>BOS</td>\n",
       "      <td>34.179279</td>\n",
       "      <td>-118.363509</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>07/21/2019 08:12:00 PM</td>\n",
       "      <td>07/23/2019 09:27:00 AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030761</th>\n",
       "      <td>NEGB_ELA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Mobile App</td>\n",
       "      <td>July</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.139627</td>\n",
       "      <td>-118.202154</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>07/21/2019 08:14:00 PM</td>\n",
       "      <td>07/22/2019 09:43:00 AM</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030762</th>\n",
       "      <td>NC</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Call</td>\n",
       "      <td>July</td>\n",
       "      <td>N</td>\n",
       "      <td>BOS</td>\n",
       "      <td>34.057328</td>\n",
       "      <td>-118.297529</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>07/21/2019 08:14:00 PM</td>\n",
       "      <td>07/26/2019 03:46:00 PM</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>115.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AssignTo             RequestType RequestSource Month Anonymous  \\\n",
       "3030758        EV             Bulky Items          Call  July         N   \n",
       "3030759        NC  Illegal Dumping Pickup          Call  July         N   \n",
       "3030760        EV             Bulky Items          Call  July         N   \n",
       "3030761  NEGB_ELA        Graffiti Removal    Mobile App  July         N   \n",
       "3030762        NC             Bulky Items          Call  July         N   \n",
       "\n",
       "        CreatedByUserOrganization   Latitude   Longitude  ElapsedDays  \\\n",
       "3030758                       BOS  34.178507 -118.362879            2   \n",
       "3030759                       BOS  34.056775 -118.297845            5   \n",
       "3030760                       BOS  34.179279 -118.363509            2   \n",
       "3030761              Self Service  34.139627 -118.202154            1   \n",
       "3030762                       BOS  34.057328 -118.297529            5   \n",
       "\n",
       "         Just Date             CreatedDate              ClosedDate    CD  \\\n",
       "3030758 2019-07-21  07/21/2019 08:11:00 PM  07/23/2019 09:28:00 AM   2.0   \n",
       "3030759 2019-07-21  07/21/2019 08:12:00 PM  07/26/2019 05:14:00 PM  10.0   \n",
       "3030760 2019-07-21  07/21/2019 08:12:00 PM  07/23/2019 09:27:00 AM   2.0   \n",
       "3030761 2019-07-21  07/21/2019 08:14:00 PM  07/22/2019 09:43:00 AM  14.0   \n",
       "3030762 2019-07-21  07/21/2019 08:14:00 PM  07/26/2019 03:46:00 PM  10.0   \n",
       "\n",
       "         LessEqualEleven  ElapsedHours  \n",
       "3030758                1     37.283333  \n",
       "3030759                1    117.033333  \n",
       "3030760                1     37.250000  \n",
       "3030761                1     13.483333  \n",
       "3030762                1    115.533333  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(679112, 6)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XCAT = dfn.filter(items = c).values\n",
    "XCAT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "start_date = '2019-12-01'\n",
    "start = datetime.strptime(start_date,'%Y-%m-%d')\n",
    "df_three = dfn[(dfn['Just Date'] <= start-timedelta(weeks=11)) &\n",
    "                   (dfn['Just Date'] >= start-timedelta(weeks=11)+relativedelta(years=-1) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssignTo</th>\n",
       "      <th>RequestType</th>\n",
       "      <th>RequestSource</th>\n",
       "      <th>Anonymous</th>\n",
       "      <th>CreatedByUserOrganization</th>\n",
       "      <th>CD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ElapsedDays</th>\n",
       "      <th>Just Date</th>\n",
       "      <th>CreatedDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2340578</th>\n",
       "      <td>NC</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service_SAN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34.082258</td>\n",
       "      <td>-118.312461</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:02:00 AM</td>\n",
       "      <td>01/04/2019 11:03:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340580</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.236888</td>\n",
       "      <td>-118.536385</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:10:00 AM</td>\n",
       "      <td>01/03/2019 12:27:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340581</th>\n",
       "      <td>WV</td>\n",
       "      <td>Illegal Dumping Pickup</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.230222</td>\n",
       "      <td>-118.539758</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:19:00 AM</td>\n",
       "      <td>01/07/2019 09:39:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340582</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.235078</td>\n",
       "      <td>-118.536392</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:28:00 AM</td>\n",
       "      <td>01/03/2019 12:28:00 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340583</th>\n",
       "      <td>WVA</td>\n",
       "      <td>Graffiti Removal</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.239704</td>\n",
       "      <td>-118.523064</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>01/01/2019 12:32:00 AM</td>\n",
       "      <td>01/03/2019 04:27:00 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AssignTo             RequestType RequestSource Anonymous  \\\n",
       "2340578       NC             Bulky Items  Self Service         N   \n",
       "2340580      WVA        Graffiti Removal  Self Service         N   \n",
       "2340581       WV  Illegal Dumping Pickup  Self Service         N   \n",
       "2340582      WVA        Graffiti Removal  Self Service         N   \n",
       "2340583      WVA        Graffiti Removal  Self Service         N   \n",
       "\n",
       "        CreatedByUserOrganization    CD   Latitude   Longitude  ElapsedDays  \\\n",
       "2340578          Self Service_SAN   4.0  34.082258 -118.312461            3   \n",
       "2340580              Self Service  12.0  34.236888 -118.536385            2   \n",
       "2340581              Self Service  12.0  34.230222 -118.539758            6   \n",
       "2340582              Self Service  12.0  34.235078 -118.536392            2   \n",
       "2340583              Self Service  12.0  34.239704 -118.523064            2   \n",
       "\n",
       "         Just Date             CreatedDate              ClosedDate  \n",
       "2340578 2019-01-01  01/01/2019 12:02:00 AM  01/04/2019 11:03:00 AM  \n",
       "2340580 2019-01-01  01/01/2019 12:10:00 AM  01/03/2019 12:27:00 AM  \n",
       "2340581 2019-01-01  01/01/2019 12:19:00 AM  01/07/2019 09:39:00 AM  \n",
       "2340582 2019-01-01  01/01/2019 12:28:00 AM  01/03/2019 12:28:00 AM  \n",
       "2340583 2019-01-01  01/01/2019 12:32:00 AM  01/03/2019 04:27:00 PM  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_three.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dfn = df.filter(items = c + d)\n",
    "    dfn = dfn.dropna()\n",
    "    #Separate data into explanatory and response variables\n",
    "    XCAT = dfn.filter(items = c).values\n",
    "    XNUM = dfn.filter(items = d).values\n",
    "    y = None\n",
    "    #Encode cateogrical data and merge with numerical data\n",
    "    onehotencoder = load('onehot.joblib')\n",
    "    XCAT = onehotencoder.transform(XCAT).toarray()\n",
    "    X = np.concatenate((XCAT, XNUM), axis=1)\n",
    "    return X, dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['WLA','Bulky Items','Self Service','January','N','Self Service',34.0144110617, -118.444726595]\n",
    "column_names = ['AssignTo', 'RequestType', 'RequestSource', 'Month', 'Anonymous', 'CreatedByUserOrganization','Latitude','Longitude']\n",
    "dictionary = dict(zip(column_names,features))\n",
    "df_request = pd.DataFrame(columns= column_names)\n",
    "for key in dictionary: \n",
    "    df_request.at[0, key] = dictionary[key] \n",
    "X, dfn = preprocess_request(df_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 1.0, 0.0, 34.0144110617, -118.444726595]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.72038993])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRT = pickle.load(open('modelCD.pkl', 'rb'))\n",
    "#formatted_request = np.array([fifty,dfn['ElapsedHours'][0]])\n",
    "modelRT.predict(a)/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AssignTo</th>\n",
       "      <th>RequestType</th>\n",
       "      <th>RequestSource</th>\n",
       "      <th>Month</th>\n",
       "      <th>Anonymous</th>\n",
       "      <th>CreatedByUserOrganization</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WLA</td>\n",
       "      <td>Bulky Items</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>January</td>\n",
       "      <td>N</td>\n",
       "      <td>Self Service</td>\n",
       "      <td>34.0144</td>\n",
       "      <td>-118.445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AssignTo  RequestType RequestSource    Month Anonymous  \\\n",
       "0      WLA  Bulky Items  Self Service  January         N   \n",
       "\n",
       "  CreatedByUserOrganization Latitude Longitude  \n",
       "0              Self Service  34.0144  -118.445  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "XCAT = dfn.filter(items = c).values\n",
    "XNUM = dfn.filter(items = d).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['WLA', 'Bulky Items', 'Self Service', 'January', 'N',\n",
       "        'Self Service']], dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6 into shape (7,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-c744862a1e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0monehotencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'onehot.joblib'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mXCAT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monehotencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXCAT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 6 into shape (7,)"
     ]
    }
   ],
   "source": [
    "onehotencoder = load('onehot.joblib')\n",
    "XCAT = onehotencoder.transform(XCAT.reshape((7,-))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fservice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2890754"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of requests that are under or equal to 11 days\n",
    "df_under = df[df['ElapsedDays'] <= 11]\n",
    "df_under.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140059"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of requests that are more than 11 days\n",
    "df_over = df[df['ElapsedDays'] > 11]\n",
    "df_over.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046211693034179276"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_over.shape[0] / (df_over.shape[0] + df_under.shape[0])\n",
    "#Very small"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
